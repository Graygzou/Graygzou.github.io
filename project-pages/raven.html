<hr />
<p>layout: project-page
title: raven
description: Top down 2D game, similar to a Quake-style deathmatch.
color: “#f34b7d”
language: C++
stargazers-count: 1
forks-count: 0
updated-at: 2019-07-22 23:23:09
last-update-days: 56
tags: [‘artificial-intelligence’, ‘top-down-shooter’, ‘neural-network’, ‘fuzzilogic’, ‘goal-oriented-action-planning’, ‘steering-behaviors’]
platforms: Windows
tools: [Visual Studio, Lua]
duration: “1 month”
team-size: 6
main-roles: [Project Manager, IA Programmer, Gameplay Programmer]
project_links:</p>
<ul>
  <li>name: github
url: https://github.com/Graygzou/raven—
<!---
Gregoire Boiron <gregoire.boiron@gmail.com>
Copyright (c) 2018-2019 Gregoire Boiron  All Rights Reserved.
---></li>
</ul>

<!---
Gregoire Boiron <gregoire.boiron@gmail.com>
Copyright (c) 2018 Gregoire Boiron  All Rights Reserved.
--->

<h2 id="overview">Overview</h2>
<p>Raven is a top down 2D game, similar to a Quake-style deathmatch. It is originaly made by Mat Bucklandin his book, “Programming Game AI By Example”. This application has been completed for a school project at the Université du Québec &amp;#224 Chicoutimi (UQAC). The course is the following : <a href="http://cours.uqac.ca/8IAR125"> Artificial Intelligence for Video Games (8IAR125).</a></p>

<p>The gameplay of Raven is similar of a Quake-style deathmatch. When starting the game, severals bots spawned controlled by similar AI trying to win, by killing as many bots as possible. Bots can also pick up health or weapons if needed. The player could also take control of a bot by clicking on it. Ones the bot is controlled, some actions were possible like firing, switching weapons, etc.</p>

<h3 id="project-goals">Project Goals</h3>
<ul>
  <li>Learn and apply AI techniques used in video games.</li>
  <li>Try making a neural network to train an AI.</li>
  <li>Improved the game by adding more modes (team deathmatch, 1vs1)</li>
  <li>Improved the game by adding more features (weapons, maps, …).</li>
</ul>

<p><span class="table_title">Github Link</span>: <a href="https://github.com/Graygzou/Raven-IA">RAVEN Project</a>.</p>

<h2 id="screenshots">Screenshots</h2>
<p>TODO: Add images ?</p>

<h2 id="detailed-info">Detailed Info</h2>
<p>All the below techniques were already in the game or added by the team into Raven.</p>

<p>The final goal was to make bots behave like human as much as possible and create the illusion to playing against thinking humans.</p>

<h3 id="added-features">Added Features</h3>
<ul>
  <li>A human player and custom controls (ZQSD movement with mouse scroll to switch weapons).</li>
  <li>Introduce “fuzzy logic” to bots.</li>
  <li>New weapon in the game : a grenade.</li>
  <li>Introduce a learning bot (create neural network and train it with game data).</li>
  <li>Two new modes : team deathmatch and Duel mode (1vs1).</li>
  <li>Three Bot behaviors for duel mode (“Burnhead”, “Coward” and “Weapon Collector”).</li>
  <li>Add a new map.</li>
</ul>

<h3 id="ia-techniques">IA techniques</h3>
<h4 id="goal-driven-agent-behavior">Goal-Driven Agent Behavior</h4>
<p>In this application Mat Buckland decided to add a “brain” to each bots in the game. This brain used goal-driven behavior to tell the bot what he should do right now based on game entries.</p>

<h4 id="goal-decomposition">Goal decomposition</h4>
<p><img class="class-diagram" src="/assets/project-images/raven/goals-composite.png" /></p>

<p>This process works just like the human brain : if you want to achieve something, you will decomposed this goal into many sub-goals easier to make archieve than the first one. And if it’s not enough yet, keep doing this until sub-goals granularity are simple enough to be code by a function or a line of code. This can be done with the composite design pattern like the picture shows.</p>

<p>We can noticed that goals have three methods :</p>
<ul>
  <li>Activate()</li>
  <li>Process()</li>
  <li>Terminate()</li>
</ul>

<p>Those are used to start a goal, keep track of the progress, and close a goal. This kind of abstraction is really useful, specially when game data make the bot change his goal priorities (ennemy showing up after passing a corner, ennemy fire coming from the back, etc.)</p>

<h4 id="goals-arbitration">Goals arbitration</h4>
<p>Once we know how to achieve each goal, we need to choose between available goals. To do so, a score is given to each goal for each update. This score is calculated with Desirability functions that take many game parameters in account and standardized to be in the range 0 (Low Desitability) to 1 (High Desirability). The goal with the highest desirability is chose to be the next goal.</p>

<p>In addition, a memory has been add to be able to stop a current goal, make some actions and resume the previous main goal.</p>

<h4 id="fuzzy-logic">Fuzzy Logic</h4>
<p>Fuzzy logic were also introduced to make bots choose their weapons based on the game context. Fuzzy logic is initially used to put values on vague linguistic terms like “small amount”, “slightly”, etc.</p>

<p>Thanks to Bayesian statistics and probabilities, we can defined a fuzzy set that describe the desirability of a weapon based on a specific parameter. By adding fuzzy rules to it, we will be able to compute the final value which will tell the bot, based on a final fuzzy set, which weapon is the best right now.</p>

<div class="bloc-images">
		    <img src="/assets/project-images/raven/ammo-fuzzy.png" />
		    <img src="/assets/project-images/raven/weapon-fuzzy.png" />
</div>

<h4 id="neural-network">Neural Network</h4>
<p>Finally, we implemented a neural network in this application to let a bot learned how to shoot. To do so, we used a multi-layer perceptron (MLP) and train it “to shoot or not” with specific inputs. Those inputs were the following :</p>
<ul>
  <li>Is the ennemy visible ? (0 or 1)</li>
  <li>Does the ennemy has maximum health ? (0 or 1)</li>
  <li>Does the learning bot has his maximum health ?</li>
  <li>The current weapon of the learning bot (6 through 9)</li>
  <li>Does the distance ennemy-learning bot is less than 200 pixels ? (0 or 1)</li>
</ul>

<p>We used the backpropagation to trained the network, which is a traditional supervised learning technique. To make sure the net was trained, we made tests with other data than our training data and we analysed results. We’ve find out that our learning process were doing good and we finally tested it in-game.</p>

<div class="bloc-images">
		<img src="/assets/project-images/raven/network.png" />
	  <img src="/assets/project-images/raven/results.png" />
</div>

<p>The final results were correct since the learning bot shoot at the other bots. We even noticed that his score were slightly higher than the average.</p>

